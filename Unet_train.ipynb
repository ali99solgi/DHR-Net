{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from torch import optim , Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from Unet_architecture import UNet,hair_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = \"D:/DOWNLOAD/DIGITAL HAIR DATASET/train/original_images/\"\n",
    "train_mask_path = \"D:/DOWNLOAD/DIGITAL HAIR DATASET/train/mask/\"\n",
    "\n",
    "val_images_path = \"D:/DOWNLOAD/DIGITAL HAIR DATASET/val/original_images/\"\n",
    "val_mask_path = \"D:/DOWNLOAD/DIGITAL HAIR DATASET/val/mask/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(input: Tensor, target: Tensor, epsilon: float = 1e-6):\n",
    "\n",
    "    sum_dim = (-1, -2, -3)\n",
    "\n",
    "    inter = 2 * (input * target).sum(dim=sum_dim)\n",
    "    sets_sum = input.sum(dim=sum_dim) + target.sum(dim=sum_dim)\n",
    "\n",
    "    dice = (inter + epsilon) / (sets_sum + epsilon)\n",
    "    \n",
    "    return dice\n",
    "\n",
    "def dice_loss(input: Tensor, target: Tensor):\n",
    "    return 1 - dice_coeff(input, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        model,\n",
    "        device,\n",
    "        epochs,\n",
    "        train_batch_size,\n",
    "        val_batch_size,\n",
    "        learning_rate,\n",
    "        weight_decay):\n",
    "\n",
    "    train_dataset = hair_dataset(images_dir=train_images_path,masks_dir=train_mask_path)\n",
    "    val_dataset = hair_dataset(images_dir=val_images_path,masks_dir=val_mask_path)\n",
    "\n",
    "    train_data = DataLoader(dataset=train_dataset,batch_size=train_batch_size,shuffle=True)\n",
    "    val_data = DataLoader(dataset=val_dataset,batch_size=val_batch_size,shuffle=False)\n",
    "\n",
    "    model.to(device=device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(),lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', factor=0.1, patience=2 , min_lr=1e-8)\n",
    "\n",
    "    # Begin Training\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        print('epoch:',epoch)\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in tqdm(train_data):\n",
    "\n",
    "            images, true_masks = batch['images'], batch['masks']\n",
    "            images = images.to(device=device)\n",
    "            true_masks = true_masks.to(device=device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            masks_pred = model(images)\n",
    "            loss = dice_loss(masks_pred.squeeze(1), true_masks)\n",
    "            epoch_loss += loss \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        #------------------------------------------------------------------------------------------------\n",
    "\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for batch in tqdm(val_data):\n",
    "\n",
    "                images, true_masks = batch['images'], batch['masks']\n",
    "                images = images.to(device=device)\n",
    "                true_masks = true_masks.to(device=device)\n",
    "\n",
    "                masks_pred = model(images)\n",
    "                loss = dice_loss(masks_pred.squeeze(1), true_masks)\n",
    "                val_loss += loss\n",
    "\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        print('Training Loss: {:.6f} \\tval Loss: {:.6f} \\tlr: {:.6f}'\n",
    "            .format(epoch_loss.item(),val_loss.item(),optimizer.defaults['lr']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet()\n",
    "\n",
    "train_model(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    epochs=50,\n",
    "    train_batch_size = 10,\n",
    "    val_batch_size = 10,\n",
    "    learning_rate=0.1,\n",
    "    weight_decay = 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'final_model.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8755eff31258cf3f68aa399e6f759d79082959dfad6f58a9830d0e0b06355a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
