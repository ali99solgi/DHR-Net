{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.inc = DoubleConv(in_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        self.down4 = Down(128, 256)\n",
    "        self.up1 = Up(256, 128)\n",
    "        self.up2 = Up(128, 64)\n",
    "        self.up3 = Up(64, 32)\n",
    "        self.up4 = Up(32, 16)\n",
    "        self.outc = OutConv(16, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        output = torch.sigmoid(logits)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hair_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, images_dir: str, masks_dir: str, scale: float = 1.0):\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.masks_dir = Path(masks_dir)\n",
    "        assert 0 < scale <= 1, 'Scale must be between 0 and 1'\n",
    "        self.scale = scale\n",
    "\n",
    "        self.ids = [file for file in listdir(images_dir) if isfile(join(images_dir, file)) and not file.startswith('.')]\n",
    "        if not self.ids:\n",
    "            raise RuntimeError(f'No input file found in {images_dir}, make sure you put your images there')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        if type(index) == int:\n",
    "            index = [index]\n",
    "\n",
    "        for idx in iter(index):\n",
    "\n",
    "            image_name = os.path.join(self.images_dir,self.ids[idx])\n",
    "            image = cv2.imread(image_name)\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            mask_name = os.path.join(self.masks_dir,self.ids[idx])\n",
    "            mask = cv2.imread(mask_name)\n",
    "            mask = cv2.cvtColor(mask,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        images = torch.tensor(image,dtype=torch.float32).permute(2,0,1)/255\n",
    "        masks = torch.tensor(mask,dtype=torch.float32)/255\n",
    "\n",
    "        sample = {'images': images, 'masks': masks}\n",
    "\n",
    "        return sample\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
